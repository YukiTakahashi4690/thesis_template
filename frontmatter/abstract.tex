%!TEX root = ../thesis.tex
\chapter*{概要}
\thispagestyle{empty}
%
\begin{center}
  \scalebox{1.5}{視覚と行動のend-to-end学習により経路追従行動を}\\
  \scalebox{1.5}{オンラインで模倣する手法の提案}\\
  \scalebox{1.5}{(オフラインでデータセットを収集して訓練する手法の検証)}
\end{center}
\vspace{1.0zh}
%

近年, 自律移動ロボットの研究が盛んに行われている. 本研究室においても, 2D-LiDARを用いた自律移動システムの出力を教師信号として与えることで, ロボットの経路追従行動をオンラインで模倣する手法を提案し, 実験を行うことで有効性を示してきた. 本研究では, 従来手法を基に, 目標とする経路上及び周辺のデータを一度に収集し, オフラインで訓練する手法を提案する. 提案手法では, 経路上にロボットを配置し, カメラ画像と教師データとなる目標角速度を収集する. それらのデータを基にオフラインで学習を行い, 学習後はカメラ画像を入力とした学習出力により自律移動する. 

\vspace{10mm}
キーワード: end-to-end学習, Navigation, オフライン
%
\newpage
%%
\chapter*{abstract}
\thispagestyle{empty}
%
\begin{center}
  \scalebox{1.3}{A proposal for an online imitation method of path-tracking}
  \scalebox{1.3}{behavior by end-to-end learning of vision and action}
  \scalebox{1.3}{(Validation of a method to collect and train dataset offline)}
\end{center}
\vspace{1.0zh}
%

Recently, autonomous mobile robots have been studied extensively. In our laboratory, we have proposed an online imitation method of a robot's path-following behavior by providing the output of a 2D-LiDAR-based autonomous mobile system as a teacher signal, and have demonstrated the effectiveness of the proposed method through experiments. In this study, we propose an off-line training method based on the conventional method by collecting data on and around the target path at a time. In the proposed method, a robot is placed on the path and collects camera images and target angular velocity as teacher data. The robot is trained off-line based on these data, and after training, the robot moves autonomously using the training output from the camera images as input.

keywords: End-to-End Learning, Nvigation, Offline 
